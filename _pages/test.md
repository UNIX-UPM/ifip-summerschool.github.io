---
title: "Program"
permalink: /test/
toc: true
toc_sticky: true
---

## Program

### Overview

### Monday, Aug 7th, 2023

** 19:00

### Tuesday, Aug 8th, 2023

** 08:30-09:00

Registration and Coffee Break

** 09:00-09:15

Introduction

** 09:15-10:15

Keynote: TODO

** 10:30-12:30

<table>
<thead><tr><td colspan="3">Track A: Paper Session 1 (Chair: TODO) </td></tr></thead>
<tbody>
<tr><td> TODO </td><td> <b>title</b><br/> <i>(authors)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_﻿#.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> abstract </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Private Training Approaches - A Primer</b><br/> <i>(Jenni Reuben and Ala Sarah Alaqra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges</b><br/> <i>(Marcela Tuler de Oliveira and Elyas Khorasani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Between the right to the protection of personal data and the right to health. Evolving EU regulatory framework on secondary use of electronic personal health data for medical research</b><br/> <i>(Paweł Hajduk)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_623.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> 1. Introduction

Secondary use of health data is a crucial element of modern medical research, aiming to achieve breakthroughs in medical treatment, especially for common and genetic diseases. Moreover, it is recognized to improve healthcare policymaking significantly [1].

Despite the importance of this issue, the existing legal framework for the secondary use of electronic personal health data for medical research purposes in the EU creates significant legal obstacles hampering the development of medical research. The main emphasis should be focused on the fragmented regulations on the national level and the uncertainty associated with the processing of identifiable personal data [2-3].

The European Health Data Space Regulation Proposal (“Regulation Proposal”) has been introduced to reduce legal barriers to the secondary use of electronic health data [4]. Simultaneously, it entails the assumption that it will not compromise data protection law, especially requirements provided by Regulation (EU) 2016/679 (“GDPR”) [4]. 

This paper aims to answer whether the Regulation Proposal meets the ambitious promise of facilitating research possibilities without compromising data protection law.
First, this paper covers the current legal framework for the secondary use of electronic personal health data in medical research in the EU. It will also be necessary to delimit the definitions of key terms, i.e., “secondary use of data,” “anonymization,” and “pseudonymization.” Next, the provisions of the Regulation Proposal on the secondary use of electronic health data are outlined. 

Finally, the central question of the anticipated effects of the Regulation Proposal on the secondary use of electronic personal health data for medical research in the context of the EU data protection law is addressed. The hypothesis is that the tension between data protection and regulation of the use of secondary data descends into the tension between fundamental rights.

This paper aims to advance the extensive research on the legal barriers to the second use of personal health data [2-3, 5-19], juxtaposing its findings with assessing the solutions in the Regulation Proposal. A caveat should be made that this paper covers scientific research. If the shape of the Proposal changes by the deadline for submission of the paper, it will be modified accordingly.

2. The existing regulatory framework

The framework for the secondary use of electronic personal health data in medical research in the EU is a multi-layered system comprising overlapping regimes at the EU and Member States’ level and fragmented sector-specific laws, which must be supplemented by specific ethical rules as well. 

The reason is the lack of a comprehensive law, which is combined with discretionary clauses in the GDPR, i.e., Article 9(4) and Article 89(2), providing Member States with a mandate to establish individual regulatory regimes [6, 13].

The fragmented regulatory framework results in ambiguity as to the legal basis for data processing [5], the impediment to interoperability [20], and a failure to provide univocal criteria for anonymization, pseudonymization, and the secondary use of data [7, 21].

3. Regulation Proposal on secondary use of health data

The Regulation Proposal was published on 3 May 2022 [4] as a part of the European Health Union and European strategy for data [22]. The legislative procedure is ongoing. The secondary use of electronic health data is regulated mainly in Chapter IV of the Proposal. In the paper, the focus is given to the following:
- purposes for the processing of secondary use of electronic health data (Article 34(1) and Article 35);
- health data access bodies as a decentralized EU regulatory infrastructure (Articles 36–37, 42–43);
- obligations of health data access bodies towards data subjects (Article 38);
- mechanism of data permits for secondary use of data (Section 3 of Chapter IV).

4. The anticipated impact of the Regulation Proposal

The Regulation Proposal aims to reduce barriers to the secondary use of electronic personal health data for medical research. Simultaneously, it is meant to follow existing EU data protection law [4]. Hence, the question arises of whether this promise is met. To answer it, the four most significant challenges at the intersection of data protection law and the Regulation Proposal, also acknowledged by the European Data Protection Board and the European Data Protection Supervisor [23], are analyzed:
- vague and overly broadly defined grounds for data processing for secondary use (Article 34(1) of the Regulation Proposal);
- blurred relation between Chapter IV of the Regulation Proposal, Article 9(4) of the GDPR, the derogation in Article 89(1) of the GDPR, and subsequent layers of Member States’ laws; it does not reduce legal uncertainty on the researchers’ side, but contributes to an even more disordered legal regime;
- exemption from information obligation in Article 14(1) of the GDPR for health data access bodies (Article 38(2) of the Regulation Proposal); it may lead to uncontrolled use of personal data without sufficient measures of control for data subjects;
- potential jurisdictional overlap between data protection authorities under the GDPR and health data access bodies (Article 36(1) of the Regulation Proposal); sufficient legal measures to collaborate and resolve disputes that might arise have not been implemented.

5. The fundamental rights perspective

The tension between data protection and effective regulation of the use of secondary data descends into the tension between the fundamental rights to health and data protection. Health care and personal data are areas at the interface because they are intended to serve different values, which, realized disproportionately, may be mutually exclusive. Consequently, tension arises over the adoption and interpretation of the law, that is, which way of exercising a particular measure will allow for the balance of the two rights. Hence, the paper analyzes these two rights, including whether the right to health is a separate fundamental right, and outlines the interplay between the right to privacy and data protection in this context, which is also essential from the legitimate interest assessment perspective.

6. References [selected bibliography]

1.	Meeting on secondary use of health data (who.int), https://www.who.int/europe/news-room/events/item/2022/12/13/default-calendar/meeting-on-secondary-use-of-health-data#:~:text=Secondary%20use%20of%20health%20data%20is%20the%20processing%20of%20health,of%20a%20service%20or%20product., last accessed 2023/03/15.
2.	Report on secondary use of health data through European case studies, Towards European Health Data Space, https://tehdas.eu/app/uploads/2022/08/tehdas-report-on-secondary-use-of-health-data-through-european-case-studies-.pdf, p. 7, last accessed 2023/03/15.
3.	Peloquin, D., DiMaio, M., Bierer, B. et al.: Disruptive and avoidable: GDPR challenges to secondary research uses of data. European Journal of Human Genetics 28, 697–705 (2020).
4.	Proposal for a REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL on the European Health Data Space, COM/2022/197 final, Document 52022PC0197.
5.	Staunton, C., Slokenberga. S., Mascalzoni. D.: The GDPR and the research exemption: considerations on the necessary safeguards for research biobanks. European Journal of Human Genetics 27, 1159-1167 (2019).
6.	Pormeister, D.: Genetic research and applicable law: the intra-EU conflict of laws as a regulatory challenge to cross-border genetic research. Journal of Law and the Biosciences 5(3), 706–723 (2018).
7.	Kindt, E., López, C.A.F., Czarnocki, J., et al.: Study on the appropriate safeguards under Article 89(1) GDPR for the processing of personal data for scientific research. Final Report. EDPS/2019/02-08. August 2021. https://edpb.europa.eu/system/files/2022-01/legalstudy_on_the_appropriate_safeguards_89.1.pdf, last accessed: 2023/03/15.
8.	Ionescu, S.: EU data protection, obstacle in the way of medical scientific research?. Academic Journal of Law and Governance 8(2), 124-128 (2020).
9.	Donnelly, D., McDonagh, M.: Health Research, Consent and the GDPR Exemption. European Journal of Health Law 26(2), 97-119 (2019).
10.	Comande, G., Schneider, G.: Differential Data Protection Regimes in Data-Driven Research: Why the GDPR Is More Research-Friendly than You Think. German Law Journal 23(4), 559-596 (2022).
11.	Timmers, M., Van Veen, E., Maas, A. I., Kompanje, E. J.: Will the EU data protection Regulation 2016/679 inhibit critical care research. Medical Law Review 27(1), 59-78 (2019).
12.	Vayena, E., Blasimme, A.: Health Research with Big Data: Time for Systemic Oversight. The Journal of Law, Medicine & Ethics 46(1), 119–129 (2018).
13.	Ho, C.: Challenges of the EU General Data Protection Regulation for biobanking and scientific research. Journal of Law, Information and Science 25(1), 84-103 (2017).
14.	Mostert, M., Bredenoord, A.L., van der Sloot, B. et al. From Privacy to Data Protection in the EU: Implications for Big Data Health Research. European Journal of Health Law 25(1), 43-56 (2018).
15.	Vukovic, J., Ivankovic, D., Habl, C. et al. Enablers and barriers to the secondary use of health data in Europe: general data protection regulation perspective. Archives of Public Health 80, 115 (2022).
16.	Amram, D.: Building up the “Accountable Ulysses” model. The impact of GDPR and national implementations, ethics, and health-data research: Comparative remarks. Computer Law & Security Review 37, 105413-105413 (2020).
17.	Hussein, R, Scherdel, L, Nicolet, F., Martin-Sanchez, F.: Towards the European Health Data Space (EHDS) ecosystem: A survey research on future health data scenarios. International Journal of Medical Informatics 170, 884-893 (2023).
18.	van Kessel, R., Wong, B. L. H., Forman, R., Gabrani, J., Mossialos, E. The European Health Data Space fails to bridge digital divides. BMJ(e) (378), e071913 (2022).
19.	Starkbaum, J., Felt, U. Negotiating the reuse of health-data: Research, big data, and the European general data protection regulation. Big Data & Society 6(2), 1-12 (2019).
20.	Boyd, M., Zimeta, M., Tennison, J., et al. Secondary use of health data in Europe Open Data Institute. Report. https://theodi.org/wp-content/uploads/2021/09/Secondary-use-of-Health-Data-In-Europe-ODI-Roche-Report-2021-5.pdf, last accessed 2023/03/15.
21.	Report on secondary use of health data through European case studies, Towards the European Health Data Space, https://tehdas.eu/app/uploads/2022/08/tehdas-report-on-secondary-use-of-health-data-through-european-case-studies-.pdf, last accessed 2023/03/15.
22.	Press Release: European Health Union: A European Health Data Space for people and science, https://ec.europa.eu/commission/presscorner/detail/en/ip_22_2711, last accessed 2023/03/15.
23.	EDPB-EDPS Joint Opinion 03/2022 on the Proposal for a Regulation on the European Health Data Space, https://edps.europa.eu/system/files/2022-07/22-07-12_edpb_edps_joint-opinion_europeanhealthdataspace_en_.pdf, last accessed 2023/03/15. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>What are You Willing to Pay to Protect Your Instagram Data? Examining the Privacy Paradox in the Social Media Context</b><br/> <i>(Paul Michel Dit Ferrer, Vera Schmitt, Arooj Anwar Khan and Ina Kern)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_728.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> A number of smartphone and web applications utilize personal information to infer user behavior, with the aim of optimizing personalized experiences and targeted advertising  [Jones and Tonetti 2020; Tang and Wang 2021]. Frequently, such applications and web services present users with only two options: accept their privacy policies or refrain from using their services. Due to the length and complexity of privacy policies, many users tend to accept the terms and conditions without a clear understanding of the potential consequences. Thus, users frequently encounter difficulty in managing the collection and distribution of their personal data, as privacy settings often do not provide transparency regarding the permissions granted to applications running in the background of smartphones. This can include access to sensitive information, such as the camera, audio, financial and location data [Crossler and Bélanger 2019]. Following recent scandals such as Cambridge Analytica and Equifax [Hinds et al . 2020], there has been a growing number of individuals expressing concern over their data privacy and online security. Nevertheless, the Privacy Paradox suggests that such concern does not necessarily translate to users taking concrete steps such as paying for protection or modifying their online behavior [Athey et al . 2017]. Thus, this research sheds more light on the empirical examination of the Privacy Paradox by running a user study with 68 participants in a concrete data sharing context of the social media platform Instagram. This research contributes to the following research questions:
(1) Can we observe the phenomenon of the Privacy Paradox in the specific context of Instagram?
(2) What is the influence of demographic indicators on privacy concern?
(3) What is the influence of demographic indicators on the monetary quantification of privacy? </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Non-Interactive Authentication Scheme for Vehicular Ad-hoc Networks: Security, Privacy, and Accountability</b><br/> <i>(Mahdi Akil and Sujash Naskar)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_951.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> Vehicular Ad-hoc Networks (VANETs) have emerged as a crucial component of modern intelligent transportation systems, providing a platform for communication among vehicles, roadside infrastructure, and other network entities. These networks facilitate various safety and efficiency applications, such as collision avoidance, traffic management, and route optimization. However, securing VANETs against malicious activities while preserving user privacy and ensuring accountability remains a complex challenge, primarily due to the dynamic and decentralized nature of the networks. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Mind The Gap: Can Air-Gaps Keep Your Private Data Secure?</b><br/> <i>(Mordechai Guri)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_1098.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> In the modern digitized world, personal data has become one of the most valuable assets and lucrative targets for attackers. This includes personal identification information (PII), medical records, legal information, biometric data, private communications, and so on.

To protect it from hackers, 'air-gap' measures might be employed. In this protective strategy, sensitive data is kept in networks that are entirely isolated (physically and logically) from the Internet. By creating a physical 'air gap' between internal networks and the outside world, data is protected from theft and online threats. Air-gap networks are relevant today to governmental organizations, healthcare industries, finance sectors, intellectual property and legal firms, and others.

In this paper, we dive deep into air-gap security in light of modern cyberattacks and data privacy. We show that despite this level of protection, publicized incidents from the last decade show that even air-gap networks are not immune to breaches. Motivated and capable adversaries can use sophisticated attack vectors to penetrate the air-gapped networks, leaking sensitive data outward. We focus on different aspects of air gap security. First, we discuss and analyze cyber incidents that target air-gap networks, including infamous ones such as Stuxnet and Agent.btz. Second, we introduce the adversarial attack model and different attack vectors attackers may use to compromise air-gap networks. Third, we present the techniques attackers can apply to leak data out of air-gap networks and introduce more innovative ones based on our recent research. We show that despite the disconnection from the Internet, attackers can exploit special types of covert channels to exfiltrate confidential data. We present the different types of covert channels, including electromagnetic, electrical, optical, thermal, and acoustic techniques, and show how attackers can use them stealthily. We also provide the technical background, implementation details, and evaluation results. Our paper shows that advanced persistent threats (APTs) can leak private and confidential information using these techniques, even when protected behind air gaps. Finally, we propose the necessary countermeasures to protect the data, both defensive and preventive. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Who is the attacker - Analyzing data protection violations in health care</b><br/> <i>(Ramona Schmidt and Ina Schiering)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_1105.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> Every natural person has the fundamental right of protection in relation to the processing of their personal data. To reinforce this right the General Data Protection Regulation (GDPR) standardizes data protection rules. Non-compliance can lead to significant fines. To ensure data protection, controllers have to understand the potential risks to data subjects. Many different persons and institutions with our without malicious intentions can pose a risk. In this paper we analyse data protection violations in the health care sector between July 2018 and March 2023 to identify the stakeholder who pose a risk to the data subjects as well as their motives. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Secure and GDPR-Compliant Authentication for Data Subject Rights Enforcement</b><br/> <i>(Malte Hansen and Andre Büttner)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_1762.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> In light of the GDPR, a data controller (DC) needs to allow a data subject (DS) to exercise certain data subject rights. A key requirement here is that DCs can reliably authenticate DSs. Due to a lack of clear technical specifications, this has been realized in different ways, such as by requesting copies of ID documents or by email address verification. However, previous research has shown that this is associated with various security and privacy risks and that identifying DSs can be a non-trivial task.
In this paper, we review different authentication schemes and propose an architecture that enables DCs to authenticate DSs in a secure and privacy-preserving manner by using the eIDAS 2.0 framework. Our work contributes to a more standardized way of authenticating DSs which will be beneficial for both DCs and DSs. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>User Interaction Data in Apps: Comparing Policy Claims to Implementations</b><br/> <i>(Feiyang Tang and Bjarte M. Østvold)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_2021.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> The use of mobile apps generates extensive user interaction data, such as swiping, zooming, or time spent on a screen, and this data often collected by apps and their services. At the same time, apps typically have inadequate disclosure of data collection in their privacy policies. For example, they might not specify the types of user interaction data they collect in the privacy policy.

We propose a way to automatically compare claims about user interaction data collection - taken from  apps' privacy policies - to data collection evidence obtained using static analysis of the apps' implementations. From privacy policies we extract text fragments related to user interaction data, converting the text into a standardized format for collection claims about user interaction data and collection techniques. Then we relate collection evidence from static analysis of apps with the corresponding collection claims from the apps' policies. This lets us point out inadequacies in the claims, effectively doing an automated fact-checking of the relevant part of the privacy policies. By providing an automated method to compare data collection implementations with data collection claims, we aim to enhance transparency and foster trust between app developers and users. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Proposal for a Tutorial: Shared, public and out of control – Your data on the public web</b><br/> <i>(Carolin Gilga)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_2128.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> It is hard to imagine today's world without the Internet. Current estimates put it as being used by around 68 percent of the world's population. The central hub of today’s Internet is the world wide web, especially social media networks such as Facebook, Instagram, or Snapchat. The reason for its success is easily apparent: The ease of public communication. Be it an opinion, a product review, or documenting everyday life, every user can effortlessly post any (self-created) content publicly on the web. However, users are often unaware of the fact that they are not only reaching out to individual users, but that public content can also be collected en masse and evalu-ated systematically by third parties. This procedure often is called web monitoring. 
So far, there is no agreed-upon definition of web monitoring, but it is generally understood as a time-critical and targeted analysis of public data from the web, that aims to gain new information on a set topic. Precisely it is about mass data processing to create additional value. This can be done for various purposes. Companies may gain competitive advantage through web trend anal-ysis or automated observing of consumers’ interests. Researchers, especially in social science, may gain essential new insights on basis of public data. Public agencies may use web monitor-ing for law enforcement, or to manage special challenges. 
While companies or authorities usually benefit from web monitoring, users often feel very un-comfortable when they become aware of their public data being used this way. The fact that many users publish their data generously on the web seems contradictory only at first glance. Representative research shows that more than 50 per cent of internet users are concerned about their privacy, but in many cases do not make arrangements to protect it. This psychological phenomenon, known as privacy paradox, encourages web monitoring as continuously new data is created that could be used.
From a legal standpoint and in view of said paradox, the question arises to which extend the us-ers are protected by the law despite their paradoxical behaviour. At first thought, one might as-sume that the usage of public data is permitted and possible for anybody without restrictions. Whether this assumption corresponds to the actual legal circumstances, however, needs to be examined more closely. For this purpose, it is necessary to take a closer look at the matter at the heart of web monitoring: the data. Applicable data protection considerations arise from both fun-damental and simple law.
Before examining the data protection legal framework, it must first be clarified when a data is to be considered ‘public’. As there is no legal definition of the term, the distinction between public and non-public data can be difficult in some cases. However, based on the considerations of the GDPR, public data is generally understood to be data that is available to a group of indetermina-ble individuals. At the same time, even access requirements do not necessary preclude the data from being public, provided the requirements are not generally exclusive.
At the fundamental rights level, public data is not given a special consideration. They are neither excluded from fundamental rights protection nor explicitly mentioned. Therefore, people who publish their data on the web are protected by fundamental rights in the same way as people who keep their data private. Only the assessment of the severity of an interference with fundamental rights can be influenced by the fact that the data is public.
Following this, public and non-public data is protected the same way at the level of simple law, too. Even though there is a GDPR provision concerning the processing of public data, it only lifts the ban on processing some very sensitive data. A legal basis for the processing itself, how-ever, is not provided. Rather the permissibility of the processing depends on the general and non-specific legal basis, just like with any other kind of data. The fact of data being public can only be considered as one criterion among others in the deliberation. Thus, a blanket privileged treatment of processing public data is not provided for by the law.
As a result, it can be concluded that data from the public web are by no means unprotected by data protection law, despite the mentioned behaviour of users. For public data the same legal requirements apply as to other kind of data. For users, however, this is not necessarily accompa-nied with a feeling of control and security, as research confirms. In view of the ongoing tech-nical developments, it rather has to be assumed that this feeling will not diminish in the future. In this respect, the data is not out of control from a legal point of view, but in fact many users may still feel like that. 
The tutorial aims to provide an understanding of the contents presented in the proposal. Within this framework the focus is on the interdisciplinarity of the topic and the interaction of the fields of psychology, technology, and law. The tutorial is intended for all who are interested regardless of their actual field of expertise. The presence of basic legal knowledge is an advantage, but not crucial for understanding. Depending on the desired depth of content, the tutorial can last one ore two hours. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>(Re)construction of Data Spaces: Socio-Technical Perspectives on Structures, Actors and Impacts</b><br/> <i>(Greta Runge)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_2161.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> The society produces, stores and analyzes more data than ever before. In ad-dition to the economic potential, the common good-oriented use of data is increasingly being discussed. In this context, data is used as a strategic re-source to meet current social and ecological challenges. On the political lev-el, great potentials are attributed to data spaces. They are expected to form the basis for innovative data-based and responsible business models as well as playing a role in shaping the common good. Structural questions about data spaces seem to be unresolved so far and there is a need for clarity and further context to the different data ecosystem constructions. This also in-cludes questions about the actors who produce and shape the socio-technical systems and decisively determine the space-constructing infrastructures. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Supporting Parents in Managing Online Privacy Risks</b><br/> <i>(Ann-Kristin Lieberknecht)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_2419.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> Although parents express concerns about their children’s personal data being collected for malicious purposes, studies have shown that parents themselves often share their children’s personal data, are not aware of certain privacy risks, or lack knowledge on how to mitigate them. This research aims to investigate strategies for supporting parents in managing their children’s online privacy risks, through a qualitative, exploratory study among media educators. The purpose of the study is to identify current knowledge, obstacles, and techniques for engaging parents in privacy education, as well as to analyse the needs of parents and media educators for support material. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Legal considerations for resilient, crisis-aware information management on Urban Data Platforms</b><br/> <i>(Jan-Philipp Stroscher, Frank Hessel, Kevin Logan, Michaela Leštáková, Martin Pietsch, Andreas Morgen and Yasin Alhamwy)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_2528.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> The operation of Urban Data Platforms enables a city or municipality to exchange information from different infrastructural and organizational sub-areas. Achieving interoperability of the affected systems is crucial to attain this goal. For this purpose, data models and interfaces must be defined uniformly for all actors. This already offers significant efficiency advantages for normal operation, but also supports response to crises and emergencies by providing a solid information base. However, these benefits can only be realized if the systems can be implemented in accordance with the applicable law. Since Urban Data Platforms processes a lot of personal data, data protection law in particular is a limiting factor. It is expedient to accompany the technical conceptualization and development legally from the beginning. At the conceptual level, it makes sense to measure the intended system architecture against the data protection principles, which express the essential objectives of the GDPR's protection concept and thus permeate the entire requirements of the GDPR. In this way, the data protection principles are also relevant for the examination of the concrete implementation. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Digital Security Controversy Analysis:  Security Rationalities in the Contemporary Debate on Privacy and Surveillance</b><br/> <i>(Cynthia Ng)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_2558.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> This research paper examines the contemporary debate on privacy and surveillance in view of the increasing adoption of encryption technologies in commodity messaging services. After the Cryptowar II in mid-2010s, signified by the Apple-FBI encryption dispute in 2015-2016, the inability to access encrypted devices or services has become an escalating concern among governments (Koops and Kosta, 2018). End-to-end encryption is taken as a promising device by technology companies to safeguard users’ privacy, but its deployment has at the same time posed challenges to law enforcement in crime investigations. Known as the “going-dark” problem, law enforcement seeks technical solutions to facilitate their navigation in the “dark” (Berkman, 2016). The “dark” here refers to the absence of content for investigations as concealed by encryption technologies. Exceptional access to end-to-end encrypted contents has been one of the solutions pushed forward by law enforcement, but the solution was criticized by security and policy experts and digital rights activists when “exceptional access” got translated into a “backdoor” and a threat to human rights. The technical discussion on exceptional access development, therefore, had pointed to a sociopolitical debate over the meanings of security, which in turn had rejected the fundamental idea of exceptional access.
My study on the contemporary debate on privacy and surveillance draws from a proposal by the UK Government Communications Headquarters (GCHQ) in 2018, in which a set of principles and a design for access to encrypted services were introduced. The proposal by GCHQ received resistance from experts, activists, and technology companies. The design to have a hidden extra “end” in end-to-end encrypted communications was being challenged discursively and technically. GCHQ’s invitation to pin down the details for exceptional access implementation became a debate over the image of user trust in digital security. Beneath the contestation was an ontic dispute over whether or not instead of the initial epistemic question posed by GCHQ about how exceptional access should be developed. As I argue through the case study, the apparent disputes on technical artifacts in a digital security controversy are in fact contestations of security rationalities.
Situated in post-Cryptowar II, this case study has captured the rejection of exceptional access along the trajectory of the privacy and surveillance debate. Connected to the rejection are the emergence of client-side scanning technology for detecting child sexual abuse materials and the formulation of internet policies such as the Online Safety Bill in the United Kingdom and the Digital Services Act in the European Union (Levy and Robinson, 2022). In broader terms, this research paper brings a critical voice to the sociotechnical development of digital secure communications, and by enriching the knowledge of security rationalities. Such knowledge would help interdisciplinary readers to comprehend the current technological and policy developments that are entangled in the contemporary debate of privacy and surveillance. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Towards privacy-preserving machine learning in sovereign data spaces: challenges and potentials</b><br/> <i>(Mehdi Akbari Gurabi, Felix Hermsen and Avikarsha Mandal)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_2779.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> The world of big data offers new ways to generate value for
organizations via sharing data. Current initiatives of data spaces such
as Gaia-X and IDS offer data-driven business models enabling access
to heterogeneous data sources as well as automating the data exchange
process between organizations. However, it confronts organizations and
customers with challenges in retaining control over their data. In this
paper, we offer the extension of usage control in the data spaces with
technical means to improve data privacy guarantees. We showcase what
data sovereignty and sovereign data spaces lack regarding privacy issues
and what risks and opportunities they entail for machine learning on
sensitive data. We analyze promising building blocks and offer a conceptual
architecture to integrate privacy-enhancing technologies for remote
data science into usage control. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Identification of international transfers of personal data</b><br/> <i>(Hugo Pascual and Jose Del Alamo)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_2937.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> Compliance with the General Data Protection Regulation (GDPR) is a mandatory requirement for all European and non-European organisations that process personal data of European citizens. Failure to comply with the regulation can result in serious damage to an organisation's image as well as fines of up to €20 million or 4\% of annual revenue. In addition, this regulation ensures that data subjects are protected and that they are guaranteed certain rights with respect to their data. The scope of the regulation dealt with in this document is international transfers of users' personal data they collect. Identifying when these transfers take place and the destination of these transfers is a challenge due to the nature of the network and the limited information that organisations provide about the destinations of the personal data. We aim to flag this identification and thereby show the risk of irregularities or breaches of GDPR that directly affect the privacy of users' personal data. This identification is not a breach in itself as the user may have given consent but coupled with an analysis of privacy policies it could show important indications of non-compliance with the legislation. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Blockchain-based Decentralized Identity Management for Healthcare Systems</b><br/> <i>(Arnaf Aziz Torongo and Mohsen Toorani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_3728.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> Blockchain-based decentralized identity management provides a promising solution to improve the security and privacy of healthcare systems and make them scalable. Traditional identity management systems are centralized, which makes them single-point-of-failure, vulnerable to attacks and data breaches, and non-scalable. In contrast, blockchain-based decentralized identity management can ensure secure and transparent access to patient data while preserving the privacy. This approach enables patients to have control over their personal health data while granting permission for medical personnel to access specific information as needed. In this paper, we propose a decentralized identity management system for healthcare applications based on Hyperledger Aries and Indy. We come up with further description of required functionalities and provide high-level procedure of network initialization, on-boarding, preparation, and revocation functionalities. The proposed solution provides improved data security, privacy, immutability, interoperability, and patient autonomy by using selective disclosure, zero-knowledge proofs, Decentralized Identifiers (DID), and Verifiable Credentials (VC). Furthermore, we discuss the potential challenges associated with implementing this technology in healthcare, and evaluate the performance and security of the proposed solution. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Privacy Analysis of the Synthetic Data using Membership Inference and Data Reconstruction Attack</b><br/> <i>(Saloni Kwatra and Vicenc Torra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_4401.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> The disclosure risk of synthetic data is still being determined. Studies show that synthetic data generation techniques generate similar data to the original data and sometimes even the exact original data. Therefore, synthetic data poses high re-identification risks. In this work, we study if the synthetic data derived from different privacy-preserving synthetic data generation techniques, including DP-CTGAN (Differentially Private Conditional Tabular Generative Adversarial Network) and PATE-CTGAN (Private Aggregation of Teacher Ensembles Conditional Tabular Generative Adversarial Network) protect from membership leakage. We refer to a recent paper that shows how to attack PCA using a Membership Inference Attack (MIA). When using membership inference attacks against Principal Component Analysis (PCA), the adversary acquires access to some of the principal components and wants to determine if a particular record was used to compute those principal components. We examine the membership leakage from the principal components if the data guardian first generates synthetic data using different privacy-preserving synthetic data generation techniques before computing the principal components. We also show a data reconstruction attack against PCA, which is a more harmful attack than MIA, and examine how much protection the privacy-preserving synthetic data generation techniques provide to users' data. Hence, we do the disclosure risk assessment of synthetic datasets and also study how much information about machine learning models (principal components of PCA in our case) is safe to share. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Assuring GDPR Conformance through Language-Based Compliance</b><br/> <i>(Chinmayi Prabhu Baramashetru, Silvia Lizeth Tapia Tarifa and Olaf Owe)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_4773.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> Existing legal regulations, such as GDPR in the EU, pressurize businesses to incorporate legal rules within their information system. However, these natural language statements motivated by legal experts have raised technical challenges to be GDPR compliant. In addition, the lack of system-level support has caused businesses to pay heavy fines and users to lose control over their data. Hence we approach a realistic model trying to reconcile the existing challenges in software implications with GDPR through programming language support. We use a policy specification language to present the operational semantics of privacy-aware active object language and provide a prototype implementation for the semantics. The program simulation is in the Maude framework, which verifies our claims that GDPR violations cannot arise in our programs. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Subscriber's Identity Privacy in 5G Networks</b><br/> <i>(Ali Haider and Mohsen Toorani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_4883.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> Mobile communications have evolved over the years. Newer
generations of mobile networks provide more security than previous gen-
erations but subscriber privacy is still a major concern. In this paper,
we provide a current systematic review of subscriber privacy in mobile
networks with a focus on the newest generations. In addition, we per-
form a formal analysis of two Authentication Key Agreement (AKA)
protocols that are proposed for 5G and claim privacy. We use Verifpal,
a formal verification tool, to conduct the security analysis. Verifpal has
some advantages over other similar tools when it comes to the analysis of
unlinkability, which is an important feature for evaluating privacy. Our
formal analysis uncovered several flaws in the confidentiality, unlinkabil-
ity, and privacy of the protocols under study. Our findings highlight the
need for additional research to develop safe and private mobile network
protocols. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Enhancing transparency through Personal Information Management Systems: current state of service offerings and considerations for further advancements</b><br/> <i>(Janina Rochon)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_5020.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> Personal Information Management Systems (PIMS), in the sense of tools allow-ing individuals to gain more control over their personal data, have been in the scope of interest of the European Data Protection Supervisor, the European Commission, privacy experts, interest groups, as well as academia, for almost a decade now. The idea has also partially found its way into legislation, for example in § 26 of the German Telekommunikation and Telemedia Act and Art. 4a (2) of the current draft of the E-Privacy Regulation. A review of the current state of developments on the market, as well as the potential of these tools for mitigating existing challenges in the field of data privacy, should be considered. This article will focus in particular on the forms in which the principle of transpar-ency can be further endorsed, as one of the most crucial components of supporting individuals in the control of their dataflows, with the three pivotal forms of its realization being consent, the right the information and the right to access.

2	Consent
The strongest focus in the context of PIMS, is clearly directed towards more us-er-friendly consent management, especially in the online environment. Consent as a legal basis has been subject to criticism from both legal professionals as well as academia, for a number of reasons. First of all certain aspects, inherently enshrined within the human behaviour, are effectively hindering data subjects from making rational decisions about the processing of their personal data. These come both in the from mental shortcuts, performed in order to mitigate cognitive overload (heuristics), as well as cognitive and behavioural biases, which deviate our think-ing from the objective reality and cause us to make systematic errors in judgment. Further aggravating these issues is the frequency of request, which effec-tively leads to fatigue, largely resulting in complete disregard for most displayed consent banners. These phenomenon’s have been used to explain the generally observed “privacy paradox”, demonstrated in the observation that the behaviours of data subjects, especially in the online environment, are largely inconsistent with their declared privacy preferences. 
In order to mitigate these issues, the use of PIMS, in the form of user operated consent platforms, has been suggested. The solutions which are current-ly being contemplated and worked on in that context will be analysed as part of this paper, in order to present general developmental tendencies, as well as exist-ing limitations. Examples include Digi.me, Meeco, Advanced Data Pro-tection Control, and Privacy AVARE. The main identified issues are a strong dependency on data controllers and in the case of independent platforms, a very limited amount of dataflows to be managed via the such, with more promis-ing solutions still being under development.

3	Right to Information
The second section provides an overview of the requirements put on controllers, with regards to the provision of information to the data subject, established in Art. 13 and 14 of the GDPR, including both the timeline and the way the relevant facts need to be presented. Afterwards, currently applicable practical hindrances in achieving that goal, namely (1) the inherent conflict of objectives originating from the regulation (2) the problem of incomplete and incorrect privacy notices and (3) the extreme differences in both visual and textual presentations of facts by differ-ent service providers are identified. As a next step, both existing and potential functionalities offered by Personal Information Management Systems, which have the potential to alleviate some of these issues are presented. These are broadly classified into interpretatory and auditing tools.
Interpretatory tools, tools serve the purpose of extracting the information rele-vant to each user from privacy policies and presenting it in a coherent and intelli-gible way, thereby in a sense providing an interpretation of the available text. They may have considerable potential in reducing the hindrances of in-consistencies and conflicting objectives for privacy policies, as they allow the presentation of the relevant information in a standardized and simplified form, at times even offering an assessment on the controllers practices. They are, however, subject to the risk of underlying inaccuracies and misrepresentations in the re-viewed policies, as these would automatically be transferred onto the analysis provided to the data subject. This inherent risk can be partially remedied through the use of auditing tools, which can compare the actual processing being per-formed by an application or webpage, with the statements made by the controller their privacy policy. This service, alongside the possibility to review the legality of these polices, might also support users in the enactment of their right to lodge a complaint with the supervisory authority, in accordance with article 77 GDPR. 

4	Right to Access
Directly related to the right to information, which follows from the principle of transparency is the right to access, laid down in Art. 15 of the GDPR. The differ-ent modalities of this right, consisting of the option to obtain confirmation, access or even a copy of one’s personal data from the controller are analyzed. An review of the current market offerings in the context of PIMS, however establishes that other than possibly acting as an intermediary in submitting a request, which are in fact predominantly focused on requesting the deletion of personal data, existing tools do not seem to focus on supporting data subjects in the exercise of this par-ticular right. This is especially surprising when taking into account its practical relevance, as well as the apparent potential for improvement, consid-ering that most individuals report negative experiences in the context of submit-ting access requests.
In that context the paper examines how in which ways tools would be able to support individuals in the exercise of their right. These suggestions are mainly based on functionalities already present in other types of application, but which have not yet been considered in the context of assisting access requests. Possible solutions include the provisions of proper identification mechanisms, on which the controller could rely; the automatic calculation of deadlines and submission of reminders, already present in common compliance tools or the assurance of secure transfer channels for the provision of a copy in accordance. Most importantly however, since users typically complain about receiving incomplete are generalized answers, the machine learning and language processing abilities of the tools used for the analysis and verification of privacy policies, could be imple-mented in order to solve this issue and generate a sort of automated follow up, against the controller.

5	Summary 
The review of the current service offering, with concerning the transparency en-hancing potential of Personal Information Management Systems identifies a num-ber of crucial development, that are in fact promising when it comes to supporting individuals in making truly free and informed choices. There are however also a number of limitations and shortcomings that are identifies in that context, which lead to the conclusion that these tools are still far, from the “user centric privacy utopia” often advertised by their supporters. Here the article attempts to pro-vide proposals for further improvements, both in the with regards to the technical set-up, as well as additional features to be considered. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Towards an affordance-based typology of Personal Data Stores</b><br/> <i>(August Bourgeus, Tim Theys, Nanouk Verhulst, Peter Mechant and Laurens Vandercruysse)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_5189.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> In order to address issues related to data privacy and data sharing, personal data store (PDS) technologies have been put forward as a potential solution. PDS technologies have gained momentum in Flanders (Flanders is the northern part of Belgium) and are being positioned as a key policy aspect and a driver for innovation.
The aim of this paper is to present a thorough review of Personal Data Stores (PDS) applications, showing strengths and limitations in aspects related to data processing, sharing and consent options, and visualization. The particular properties of each PDS are presented, focusing on affordances for managing personal data, giving granular control over personal data, and over how that data is shared and used. As such, we provide a timely review and classification of PDS. 
A typology is created to map the complexity of this new data ecology with the purpose of highlighting commonalities rather than distinctions. Thus, the framework can serve as a heuristic device for considering the broader implications for data privacy and data sharing. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>K-Anonymous Privacy Preserving Manifold Learning</b><br/> <i>(Sonakshi Garg and Vicenc Torra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_5350.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> In this modern world of digitalization, abundant amount of data is being generated. This often leads to data of high dimension, making data points far-away from each other. Such data may contain confidential information and must be protected from disclosure. Preserving privacy of this high-dimensional data is still a challenging problem. This paper aims to provide a privacy preserving model to anonymize high-dimensional data maintaining the manifold structure of the data. Manifold Learning hypothesize that real-world data lie on a low-dimensional manifold embedded in a higher-dimensional space. This paper proposes a novel approach that uses geodesic distance in manifold learning methods such as ISOMAP and LLE to preserve the manifold structure on low-dimensional embedding. Later on, anonymization of such sensitive data is achieved by M-MDAV, the manifold version of MDAV using geodesic distance. MDAV is a micro-aggregation method, which works on the principle of K-Anonymity. Finally, to evaluate the efficiency of the proposed approach machine learning classification is performed on the anonymized lower-embedding. To emphasize the importance of geodesic-manifold learning, we compared our approach with a baseline method in which we try to anonymize high-dimensional data directly without reducing it onto a lower-dimensional space. We evaluate the proposed approach over natural and synthetic data such as tabular, image and textual data sets, and then empirically evaluate the performance of the proposed approach using different evaluation metrics viz. accuracy, precision, recall and K-Stress. We show that our proposed approach is providing accuracy up to 99% and thus, provides a novel contribution of analyzing the effects of K-anonymity in manifold learning. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Cybersecurity of Critical Infrastructures</b><br/> <i>(Sabarathinam Chockalingam)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_5401.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> This tutorial will address several topics within the following considering the audience of 18th IFIP Summer School on Privacy and Identity Management: (i) Regulations of cybersecurity, (ii) Cybersecurity standards and how they apply for different market verticals, (iii) Artificial Intelligence (AI) and Machine Learning (ML) for cybersecurity, (iv) Threat intelligence and analytics, (v) Human factors in cybersecurity, and (vi) Regulations and compliance in cybersecurity. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Entangled: A Case Study of Data Exchange and Actor Relationships in a Mobility Ecosystem</b><br/> <i>(Daniel Richter)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_5497.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> With the continuous proliferation of digital services, the question of personal data sharing becomes an ever-pressing issue. Contemporary solutions such as identity management raise privacy questions for customers, as the interoperability between different service providers requires substantial integration efforts. Self-sovereign identity (SSI) is an approach leveraging digital credentials promising to provide privacy-friendly data sharing to users and to enable interconnected ecosystems based on a common infrastructure. While the creation of governance frameworks has been identified as a major challenge in implementing SSI, the scarce research on this subject mainly focuses on the technical subsystem. This paper presents a case study of an urban mobility ecosystem showcasing relevant governance aspects based on data exchange, actor relationships, as well as service offerings. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Towards Enabling Digital Sovereignty of the AI Marketplace</b><br/> <i>(Venkata Satya Sai Ajay Daliparthi, Nurul Momen, Kurt Tutschku and Miguel De Prado)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_5566.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> In recent years, a wide range of data economies emerged to facilitate the trade and exchange of data goods. This work focuses on defining protocols to introduce the design of a sovereign data economy that includes ownership-preserving data trading, one-to-many collective price negotiation, and an automated data rating system. The protocols are use case driven, defined through requirements engineering, and implemented in a decentralized manner. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Towards User Definitions of Privacy Factors on IoT Trigger-Action apps</b><br/> <i>(Piero Romare, Victor Morel, Farzaneh Karegar and Simone Fischer-Hübner)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_6268.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> Internet of Things (IoT) devices benefit from sharing personal data to better meet users’ wishes and provide personalized services. During the last decade, Trigger-Action platforms like IFTTT, Zapier, and Microsoft Power Automate have enabled end-users to automatize their own digital environment. It is easier than ever to connect multiple services or devices in a workflow by utilizing the formula ”if-this-then-that”. The opportunity of End-User Development (EUD) allows for simple IoT programming of complex processes of users’ automated behavior which can eventually save users’ time in their digital activities. While this technology offers a lot of benefits, it also creates potential threats to users’ privacy. Since personal data from the users’ IoT device typically flows to more than one service provider that is involved in the corresponding “if-this-then- that” transactions, the online data flow opens a new set of privacy risks. This data flow can be illustrated briefly by the following example use case: if arrived at the office then start the smart vacuum cleaner at home. The example demonstrates the user’s personal data sharing between the smartphone that sends the trigger, knowing the location, to the smart vacuum cleaner device. Despite the users’ rights to privacy, a friendly and transparent system between the services and devices to which users can connect and automate their IoT apps, such as usable privacy tools, implemented with users’ requirements are still rarely considered. It is necessary to improve the effectiveness of users’ informed decisions since the automation of their data flow that connects the IoT apps and their active participation as actors in programming their own digital environment. To design usable permission management systems which help connect and automate IoT apps, services, and devices, we need to start from the end user’s understanding of the factors that impact their digital life, with a focus on the protection requirements of users’ privacy following their preferences and expectations. Violations of privacy expectations as well as non-compliance with legal rules could damage the user and represent extensive barriers to IoT usage. To create IoT services and systems that protect privacy, system designers and developers must comprehend which aspects can affect how individuals perceive their privacy in an IoT context.
The CyberSecIT project has the objective to develop user-friendly permissions settings that respect users’ privacy choices and ensure security for IoT automation apps. We follow a human-centered design by engaging the end-users
2 ...
for garnering their privacy expectations and concerns to develop usable permission management systems.
As the first step to reach our research objective, we aim to address the following research questions:
– RQ1: What factors impact the users’ privacy preferences for the data flow between IoT entities in the Trigger Action Platforms (TAPs) context?
– RQ2: How do the users’ privacy preferences concerning TAPs differ from the preferences reported in the literature on traditional IoT applications?
We ran three focus groups where the topic was opinions and perceptions of IoT application scenarios involving IoT Trigger-Action. We aim to extract feedback and insights from users, using the funnel technique to avoid possibilities of biases, about their privacy concerns and perspectives regarding trigger-action applications. We recruited 15 participants to extract the potential requirements and needs. We developed and proposed a sorting task on the privacy factors discussed and extracted during those focus groups. The listing of such factors happened after general and scenario-based discussions around users’ opinions, preferences, and concerns about TAPs and three specific related scenarios, the two moderators listed the privacy factors they extracted from the participants’ comments. We agreed with the participants about terms and definitions of perceived privacy concerns and asked for potential improvements to such a list. Before the conclusion, we got the ranks of the sorting task and the explanations from the participants of reason in the choice of the first ranked factor. In a collaborative way with the participants, we extracted value from their considerations. They provided many privacy concerns related to IoT Trigger-Action apps, such as control of data before the action, unexpected data handling practices, and concerns for bystanders.
To map our findings, we performed an exploratory literature review to investigate consumers’ privacy concerns raised throughout the creation and design of the IoT domain and we compared it with the TAPs context. This research intended to provide an overview and a better comprehension of present demands and needs. Overall, this paper would highlight the importance of addressing privacy concerns in the specific context of IoT Trigger-Action apps and its difference and similarity with the general IoT field. In the more general context of IoT privacy, it has been shown that the users find the protection settings complex since they lack security configurations awareness such as types of personal information collected and how data is shared [1]. Individual preferences and expectations as well as social norms play a role in users’ level of comfort and acceptance of data collection [2]. In smart home IoT the indicated concerns are related to data storage in particular what and where, how and from whom such data can be accessed [3]. To support the privacy by design development of IoT technology, we want to emphasize the importance of supporting the end-users in their privacy permissions management in Trigger-Action applications. By recognizing the potential obstacles and threats, we may build and deploy more reliable and trustworthy IoT systems that satisfy users’ privacy expectations and needs. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Integration of Verifiable Credentials in Centralized Identity Management via OAuth 2.0</b><br/> <i>(Aytaj Badirova, Faraz Fatemi Moghaddam and Ramin Yahyapour)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_6308.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> This paper describes a method for integrating self-sovereign identity with centralized identity management systems through the use of verified credentials in collaborative environments, particularly in academia. The idea is to improve the scalability and functionality of authentication while leaving authorization largely unchanged and giving users more control over their data. The proposed method makes use of the OAuth 2.0 architecture since it provides a flexible and compatible framework for handling authorization. The suggested approach supports the eIDAS project’s ”Student mobility” idea. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>THE ESSENTIAL FEATURES OF TOOLS TO ENHANCE USER CONTROL OVER PERSONAL DATA</b><br/> <i>(Alexandre Humain-Lescop)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_6322.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> Are we being too ambitious by promising “control tools” to the data subject? Digital technologies such as digital interfaces, applications, software or web pages present opportunities to give data subject more control. But is that achievable? To what extent is it the priority of those who provide these technologies? User empowerment cuts both ways. It is supposed to promote human autonomy, but it may have adverse effects, including giving him the illusion of control. 

It is therefore necessary to clarified what these control tools correspond to, and to determine the characteristics they should respect to effectively increase user control as they are supposed to do. 

This article first proposes an inventory of the various tools and concepts that are sometimes very close, sometimes encouraged by public bodies, but generally freely and uncoordinatedly developed by the market : PETs - Privacy Enhancing Technologies, TETs - Transparency Enhancing Technologies, PIMS - Personal Information Management System, Privacy dashboards, CMP - Consent Management Platforms, PDS - Personal Data Stores, DIW - Digital Identity Wallet from the proposal for a revision of the eIDAS Regulation, Data Intermediation Services from the Data Governance Act, and many others. 

Then the article confronts these tools to mechanisms that could impact user control, dealing with the notions of information, consent and more generally with the exercise of rights such as data portability, right of access, etc. Aware of the limits of GDPR and fundamental rights texts that are not always a perfect guarantee of user control, this article proposes to go beyond the law by determining “fundamental features” that control tools should carry. These fundamental characteristics allow to pre-check to what extent a given tool can pretend to really maximize the user control or not, even if it seems here more realistic to expect from a control tool to tick as many boxes as possible than all of them. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Consumer data and technology: consumer-data subject protection tools</b><br/> <i>(Kristýna Bónová)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_6999.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> In my work, I focus on how technologies monitor on consumers’ behavior online and how sophisticated data analysis made by trad-ers can lead to a business strategy when consumer privacy is at risk of being violated. The key questions of this paper are following: whether the GDPR appropriately protects consumers against ma-nipulative business strategies where personal data of many con-sumers are being processed, to what extent is the protection divid-ed between data protection law and consumer law and whether we should adopt more collective-oriented data protection legislation.
The paper consists of three main parts. In the first chapter, I de-scribe the types of surveillance technologies, how they work and what is their influence on consumer data analysis. In the second chapter, I then deal with how the individual-oriented GDPR applies to consumer data, regarding their collective character, and I focus on current tools of consumer law. In the last chapter, I deal with the property and liability principle and possible solution through the orientation on protection of the environment and compensation. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Privacy and Utility Evaluation of Synthetic Data for Machine Learning</b><br/> <i>(Felix Hermsen and Avikarsha Mandal)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_7082.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> Synthetic data generation approaches have recently received a lot of attention as a possible alternative for testing and benchmarking machine learning experiments due to the limited availability of real-world datasets. However, synthetic data generated from real datasets raises privacy concerns such as inference attacks. Whereas differentially private generative models are generally considered immune to privacy attacks, it is not straightforward how these models preserve privacy with adequate utility. In this work, we evaluate privacy-utility trade-offs on different state-of-art generative models in mixed tabular data setting. Our experimentations are performed on Mimic 3, adult census and bank marketing datasets and show the importance of selecting optimal epochs for training to achieve privacy-utility trade-offs. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Non-human Agency: Algorithmic Surveillance and Article 8 of the ECHR</b><br/> <i>(Isabella de Melo)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_7635.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> Today, technology is easier, cheaper, and more accurate. Consequently, surveillance has increased in the public sector with the purpose of law enforcement and public safety, but also in the private sector aiming targeted advertisement. At the center of surveillance technologies are big data, artificial intelligence (AI) and machine learning (ML). In this paper, I will look at state-sponsored surveillance practices that employ intelligent algorithms, which I will call “algorithmic surveillance”, in the context of cyberspace. 
I analyze the practice of state-owned digital algorithmic surveillance of natural persons’ communication in the digital realm from a human rights perspective in the European context, using the framework of the European Convention on Human Rights.  As it is well-known surveillance affects diverse interests, values, and rights. This paper is concerned with whether or not algorithmic surveillance is compatible with the human right to privacy, provided for in Article 8 of the European Convention on Human Rights. To answer my research problem, I follow the approach typically followed by the European Court of Human Rights to analyze cases of communication surveillance, from a critical point of view.
I believe that one of the great contributions of the proposed line of investigation is to think of the AI system as an agent rather than an instrument of the state. Within security agencies, we can think of AIs and humans working to operationalize a surveillance program. The AI system can be an instrument and/or an agent; what I explore conceptually is whether its nature as an agent interferes with the meaning of what 'interference' in privacy is and whether the 'safeguards' developed by the ECtHR are still adequate, considering that the use of this technology will be more and more frequent and more advanced as well. It is questionable whether the degree of sophistication of the program implies a change in thinking about the legal system and its concepts.
Non-human agency and law is a topic that is much discussed in the literatures on topics such as intellectual property law, the use of drones for military purposes and environmental law, but which I think is not sufficiently addressed in the ILHR.  I analyze human rights agency in the surveillance context, but this could also be done in the context of content moderation and of confidentiality of communication, more specifically communication between machines (M2M) or between human and machine. That is why I will leverage the literature from these other topics to discuss the object of study of this work. Throughout my work, I focus on judicial decisions -  such as Szabó and Vissy v. Hungary (2016), Roman Zakharov v. Russia (2015), Centrum for rättvisa v. Sweden (2021) and Big Brother Watch and Other v. the United Kingdom (2021) - because they are more recent and are related to technological advances, algorithms and artificial intelligence. I will also draw on work from leading scholars and legal practitioners on surveillance, artificial intelligence, and criminal justice.
Besides analyzing how the ECHR deals with the violation of privacy by non-human actors, to be more specific, the case of algorithmic surveillance, pursuant to article 8 of the ECHR, I also intend to: (i) identify what distinguishes algorithmic surveillance from other analogue technologies or techniques used for security and law enforcement; ( ii ) determine the extent and conditions under which AI systems may be legally used by surveillance programs; (iii) discuss what privacy is, what data protection is and what it should be in this digital world; (iv) assess whether the relevant legal framework is still adequate for the era of algorithmic surveillance.
It is hard to assess the adequacy of a legal framework when the technology is changing in such a fast pace, but it is undeniable necessary. So far, I believe that the system must be rethought. What I am researching is what are the characteristics of algorithmic surveillance that defy current human rights tests and what are the gaps and challenges found in the system in order to make suggestions to overcome these deficiencies. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Shared data in a European Health Data Space using the example of digital health applications</b><br/> <i>(Fabiola Böning)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_7666.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> The proposal for the regulation on the European Health Data Space concerns the improved access to electronic health data and the extended possibilities for prima-ry and secondary use. However, there are certain difficulties to expect consider-ing the detailed legislation framework in individual cases such as digital health applications in Germany. The paper shall discuss these difficulties which might occur by applying the regulations of the proposal as well as other important laws and legislations on different levels. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Towards better whistleblowing processes: understanding  privacy risks and resulting harms</b><br/> <i>(Samuel Wairimu)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_8210.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> Generally, data protection in external whistleblowing channels is significant in that it prevents the identification and retaliation of whistleblowers. In the context of journalism and external whistleblowing channels, the need for data protection is essential to ensure not only trust and confidentiality of shared information but also the protection of the whistleblower's identity, including any third parties.  However, privacy weaknesses in terms of poor data protection measures within or design flaws of external whistleblowing channels could result in privacy harms that can affect the rights and freedoms of a whistleblower and any third parties. This abstract identifies the risks that can be exploited within external whistleblowing channels, in the context of journalism, to result in feared events and, ultimately, privacy harms. In addition, we propose privacy recommendations that can be integrated into external whistleblowing channels to ensure the protection of whistleblowers in journalism. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Economics of Privacy and the Relation to Users’ Trust</b><br/> <i>(Vera Schmitt, Tingyu Song and Danila Ferents)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_8265.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> Data markets have become an important aspect of the digital economy, enabling companies to trade personal information for financial gain [Spiekermann et al . 2015]. Real-time Bidding (RTB) technology allows advertisers to bid on targeting an advertisement to a specific user in an automated auction process. It is predicted that the RTB market is going to reach 158 billion $ by 2030 [Insights 2022]. Despite efforts made towards regulating the access and processing of personal information with the General Data Protection Regulation (GDPR), there are still significant challenges when applying the GDPR in technical means [Massé 2021; Veale and Zuiderveen Borgesius 2022]. Thus, the effectiveness of such regulations remains limited and often vague, also in the RTB context. Significant public concerns about the protection of personal information and privacy have been raised after several cases of data violations and abuse with serious consequences [Gundersen 2020]. With the growing awareness of personal data privacy, an increasing number of people are seeking data protection services to secure their personal information online. These developments shed light on the research domain of the economics of privacy [Lipovetsky et al. 2011] to develop applicable solutions to provide users with more options to protect their privacy, for example by paying with money for services and applications than paying with data [Acquisti et al . 2016; Li et al. 2021; Prince and Wallsten 2020; Schmitt et al . 2021]. Moreover, it remains often unclear for the users how their data is used and processed, and how companies profit from processing or selling personal information [Lind and Boomgaarden 2019]. Therefore, this research aims to shed some light on the question, of whether users would be willing to pay (WTP) more money when receiving information about RTB markets and how companies profit from personal data often shared online. This research aims to answer the following research questions by confronting participants in a user experiment with information about RTB markets in comparison to a control group, not receiving any additional information: (1) What is the influence of Trust towards a data requestor on WTP and WTA? (2) What is the influence of negative experiences of data misuse and intrusion on WTP and WTA? (3) How does trust relate to previous negative experiences with data misuse? </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>A Framework for Exploring Personal Data Transparency from a Theoretical Perspective – Workshop Proposal –</b><br/> <i>(Anette Siebenkäs)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_9899.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> Personal Data Transparency (PDT), i.e. transparency as insight into which personal data are collected, processed, passed on to third parties, for what purpose, and for what time, is an important prerequisite of privacy and a key issue of EU data protection legislation. Research into how to establish an appropriate PDT could benefit from a theoretical foundation. In the workshop, a framework for analysis and explanation of PDT is presented and evaluated with the participants. </td><td> &nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Compliance By Design: Balancing Data Protection, Cybersecurity and AI Regulation in Software and System Development</b><br/> <i>(Bjørn Aslak Juliussen)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_9938.pdf"><img src="/assets/images/pdficon.png" border="0" /></a></td></tr><tr><td>&nbsp;</td><td> This paper explores the concept of compliance by design in
software and systems, focusing on the integration of legal requirements
into software and system development processes. The paper analyses the
impact of the General Data Protection Regulation (GDPR), the Network
and Information Security (NIS) 2 Directive, and the proposed AI Act
in the EU, examining the interplay and potential conflicts between the
requirements in these regulations. The paper concludes with a set of
recommendations for software developers for concurrent compliance with
these three rule sets. </td><td> &nbsp;</td></tr>
</tbody>
<thead><tr><td colspan="3">Track B: Paper Session 2 (Chair: TODO) </td></tr></thead>
<tbody>
<tr><td> TODO </td><td> <b>Private Training Approaches - A Primer</b><br/> <i>(Jenni Reuben and Ala Sarah Alaqra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td>&nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges</b><br/> <i>(Marcela Tuler de Oliveira and Elyas Khorasani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td>&nbsp;</td></tr>
</tbody>
<thead><tr><td colspan="3">Track C: Paper Session 3 (Chair: TODO) </td></tr></thead>
<tbody>
<tr><td> TODO </td><td> <b>Private Training Approaches - A Primer</b><br/> <i>(Jenni Reuben and Ala Sarah Alaqra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td>&nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges</b><br/> <i>(Marcela Tuler de Oliveira and Elyas Khorasani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td>&nbsp;</td></tr>
</tbody>
</table>

** 13:30-15:00

<table>
<thead><tr><td colspan="3">Track A: Paper Session 4 (Chair: TODO) </td></tr></thead>
<tbody>
<tr><td> TODO </td><td> <b>Private Training Approaches - A Primer</b><br/> <i>(Jenni Reuben and Ala Sarah Alaqra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td>&nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges</b><br/> <i>(Marcela Tuler de Oliveira and Elyas Khorasani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td>&nbsp;</td></tr>
</tbody>
<thead><tr><td colspan="3">Track B: Paper Session 5 (Chair: TODO) </td></tr></thead>
<tbody>
<tr><td> TODO </td><td> <b>Private Training Approaches - A Primer</b><br/> <i>(Jenni Reuben and Ala Sarah Alaqra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td>&nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges</b><br/> <i>(Marcela Tuler de Oliveira and Elyas Khorasani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td>&nbsp;</td></tr>
</tbody>
<thead><tr><td colspan="3">Track C: Paper Session 6 (Chair: TODO) </td></tr></thead>
<tbody>
<tr><td> TODO </td><td> <b>Private Training Approaches - A Primer</b><br/> <i>(Jenni Reuben and Ala Sarah Alaqra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td>&nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges</b><br/> <i>(Marcela Tuler de Oliveira and Elyas Khorasani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td>&nbsp;</td></tr>
</tbody>
</table>

** 15:15-16:15

** 19:00

### Wednesday, Aug 9th, 2023

** 09:00-10:00

** 10:15-12:15

<table>
<thead><tr><td colspan="3">Track A: Paper Session 7 (Chair: TODO) </td></tr></thead>
<tbody>
<tr><td> TODO </td><td> <b>Private Training Approaches - A Primer</b><br/> <i>(Jenni Reuben and Ala Sarah Alaqra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td>&nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges</b><br/> <i>(Marcela Tuler de Oliveira and Elyas Khorasani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td>&nbsp;</td></tr>
</tbody>
<thead><tr><td colspan="3">Track B: Paper Session 8 (Chair: TODO) </td></tr></thead>
<tbody>
<tr><td> TODO </td><td> <b>Private Training Approaches - A Primer</b><br/> <i>(Jenni Reuben and Ala Sarah Alaqra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td>&nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges</b><br/> <i>(Marcela Tuler de Oliveira and Elyas Khorasani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td>&nbsp;</td></tr>
</tbody>
<thead><tr><td colspan="3">Track C: Paper Session 9 (Chair: TODO) </td></tr></thead>
<tbody>
<tr><td> TODO </td><td> <b>Private Training Approaches - A Primer</b><br/> <i>(Jenni Reuben and Ala Sarah Alaqra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td>&nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges</b><br/> <i>(Marcela Tuler de Oliveira and Elyas Khorasani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td>&nbsp;</td></tr>
</tbody>
</table>

** 13:15-14:15

<table>
<thead><tr><td colspan="3">Track A: Paper Session 10 (Chair: TODO) </td></tr></thead>
<tbody>
<tr><td> TODO </td><td> <b>Private Training Approaches - A Primer</b><br/> <i>(Jenni Reuben and Ala Sarah Alaqra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td>&nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges</b><br/> <i>(Marcela Tuler de Oliveira and Elyas Khorasani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td>&nbsp;</td></tr>
</tbody>
<thead><tr><td colspan="3">Track B: Paper Session 11 (Chair: TODO) </td></tr></thead>
<tbody>
<tr><td> TODO </td><td> <b>Private Training Approaches - A Primer</b><br/> <i>(Jenni Reuben and Ala Sarah Alaqra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td>&nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges</b><br/> <i>(Marcela Tuler de Oliveira and Elyas Khorasani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td>&nbsp;</td></tr>
</tbody>
<thead><tr><td colspan="3">Track C: Paper Session 12 (Chair: TODO) </td></tr></thead>
<tbody>
<tr><td> TODO </td><td> <b>Private Training Approaches - A Primer</b><br/> <i>(Jenni Reuben and Ala Sarah Alaqra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td>&nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges</b><br/> <i>(Marcela Tuler de Oliveira and Elyas Khorasani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td>&nbsp;</td></tr>
</tbody>
</table>

** 14:30-15:30

** 19:00 Summer School Dinner

### Thursday, Aug 10th, 2023

** 09:00-11:00

** 11:15-12:45

** 12:45-14:15

** 14:30-15:30

** 16:30

### Friday, Aug 11th, 2023

** 09:00-11:00

** 11:15-12:45

** 12:45-13:15


<table>
<thead><tr><td> </td><td> </td><td> </td></tr></thead>
<tbody>
<tr><td> TODO </td><td> <b>title</b><br/> <i>(authors)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_﻿#.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> abstract </td><td>&nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Private Training Approaches - A Primer</b><br/> <i>(Jenni Reuben and Ala Sarah Alaqra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td>&nbsp;</td></tr>
<tr><td> TODO </td><td> <b>Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges</b><br/> <i>(Marcela Tuler de Oliveira and Elyas Khorasani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td>&nbsp;</td></tr>
</tbody>
</table>

<table>
<thead><tr><td> </td><td> </td><td> </td></tr></thead>
<tbody>
<tr><td><!-- ﻿# --> TODO </td><td> <b>title</b><br/> <i>(authors)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_﻿#.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 401 --> TODO </td><td> <b>Private Training Approaches - A Primer</b><br/> <i>(Jenni Reuben and Ala Sarah Alaqra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf"><img src="/assets/images/pdficon.png"border="0"></a></td></tr>
<tr><td><!-- 432 --> TODO </td><td> <b>Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges</b><br/> <i>(Marcela Tuler de Oliveira and Elyas Khorasani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 623 --> TODO </td><td> <b>Between the right to the protection of personal data and the right to health. Evolving EU regulatory framework on secondary use of electronic personal health data for medical research</b><br/> <i>(Paweł Hajduk)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_623.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 728 --> TODO </td><td> <b>What are You Willing to Pay to Protect Your Instagram Data? Examining the Privacy Paradox in the Social Media Context</b><br/> <i>(Paul Michel Dit Ferrer, Vera Schmitt, Arooj Anwar Khan and Ina Kern)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_728.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 951 --> TODO </td><td> <b>Non-Interactive Authentication Scheme for Vehicular Ad-hoc Networks: Security, Privacy, and Accountability</b><br/> <i>(Mahdi Akil and Sujash Naskar)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_951.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 1098 --> TODO </td><td> <b>Mind The Gap: Can Air-Gaps Keep Your Private Data Secure?</b><br/> <i>(Mordechai Guri)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_1098.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 1105 --> TODO </td><td> <b>Who is the attacker - Analyzing data protection violations in health care</b><br/> <i>(Ramona Schmidt and Ina Schiering)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_1105.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 1762 --> TODO </td><td> <b>Secure and GDPR-Compliant Authentication for Data Subject Rights Enforcement</b><br/> <i>(Malte Hansen and Andre Büttner)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_1762.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 2021 --> TODO </td><td> <b>User Interaction Data in Apps: Comparing Policy Claims to Implementations</b><br/> <i>(Feiyang Tang and Bjarte M. Østvold)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_2021.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 2128 --> TODO </td><td> <b>Proposal for a Tutorial: Shared, public and out of control – Your data on the public web</b><br/> <i>(Carolin Gilga)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_2128.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 2161 --> TODO </td><td> <b>(Re)construction of Data Spaces: Socio-Technical Perspectives on Structures, Actors and Impacts</b><br/> <i>(Greta Runge)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_2161.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 2419 --> TODO </td><td> <b>Supporting Parents in Managing Online Privacy Risks</b><br/> <i>(Ann-Kristin Lieberknecht)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_2419.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 2528 --> TODO </td><td> <b>Legal considerations for resilient, crisis-aware information management on Urban Data Platforms</b><br/> <i>(Jan-Philipp Stroscher, Frank Hessel, Kevin Logan, Michaela Leštáková, Martin Pietsch, Andreas Morgen and Yasin Alhamwy)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_2528.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 2558 --> TODO </td><td> <b>Digital Security Controversy Analysis:  Security Rationalities in the Contemporary Debate on Privacy and Surveillance</b><br/> <i>(Cynthia Ng)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_2558.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 2779 --> TODO </td><td> <b>Towards privacy-preserving machine learning in sovereign data spaces: challenges and potentials</b><br/> <i>(Mehdi Akbari Gurabi, Felix Hermsen and Avikarsha Mandal)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_2779.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 2937 --> TODO </td><td> <b>Identification of international transfers of personal data</b><br/> <i>(Hugo Pascual and Jose Del Alamo)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_2937.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 3728 --> TODO </td><td> <b>Blockchain-based Decentralized Identity Management for Healthcare Systems</b><br/> <i>(Arnaf Aziz Torongo and Mohsen Toorani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_3728.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 4401 --> TODO </td><td> <b>Privacy Analysis of the Synthetic Data using Membership Inference and Data Reconstruction Attack</b><br/> <i>(Saloni Kwatra and Vicenc Torra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_4401.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 4773 --> TODO </td><td> <b>Assuring GDPR Conformance through Language-Based Compliance</b><br/> <i>(Chinmayi Prabhu Baramashetru, Silvia Lizeth Tapia Tarifa and Olaf Owe)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_4773.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 4883 --> TODO </td><td> <b>Subscriber's Identity Privacy in 5G Networks</b><br/> <i>(Ali Haider and Mohsen Toorani)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_4883.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 5020 --> TODO </td><td> <b>Enhancing transparency through Personal Information Management Systems: current state of service offerings and considerations for further advancements</b><br/> <i>(Janina Rochon)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_5020.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 5189 --> TODO </td><td> <b>Towards an affordance-based typology of Personal Data Stores</b><br/> <i>(August Bourgeus, Tim Theys, Nanouk Verhulst, Peter Mechant and Laurens Vandercruysse)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_5189.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 5350 --> TODO </td><td> <b>K-Anonymous Privacy Preserving Manifold Learning</b><br/> <i>(Sonakshi Garg and Vicenc Torra)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_5350.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 5401 --> TODO </td><td> <b>Cybersecurity of Critical Infrastructures</b><br/> <i>(Sabarathinam Chockalingam)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_5401.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 5497 --> TODO </td><td> <b>Entangled: A Case Study of Data Exchange and Actor Relationships in a Mobility Ecosystem</b><br/> <i>(Daniel Richter)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_5497.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 5566 --> TODO </td><td> <b>Towards Enabling Digital Sovereignty of the AI Marketplace</b><br/> <i>(Venkata Satya Sai Ajay Daliparthi, Nurul Momen, Kurt Tutschku and Miguel De Prado)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_5566.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 6268 --> TODO </td><td> <b>Towards User Definitions of Privacy Factors on IoT Trigger-Action apps</b><br/> <i>(Piero Romare, Victor Morel, Farzaneh Karegar and Simone Fischer-Hübner)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_6268.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 6308 --> TODO </td><td> <b>Integration of Verifiable Credentials in Centralized Identity Management via OAuth 2.0</b><br/> <i>(Aytaj Badirova, Faraz Fatemi Moghaddam and Ramin Yahyapour)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_6308.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 6322 --> TODO </td><td> <b>THE ESSENTIAL FEATURES OF TOOLS TO ENHANCE USER CONTROL OVER PERSONAL DATA</b><br/> <i>(Alexandre Humain-Lescop)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_6322.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 6999 --> TODO </td><td> <b>Consumer data and technology: consumer-data subject protection tools</b><br/> <i>(Kristýna Bónová)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_6999.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 7082 --> TODO </td><td> <b>Privacy and Utility Evaluation of Synthetic Data for Machine Learning</b><br/> <i>(Felix Hermsen and Avikarsha Mandal)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_7082.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 7635 --> TODO </td><td> <b>Non-human Agency: Algorithmic Surveillance and Article 8 of the ECHR</b><br/> <i>(Isabella de Melo)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_7635.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 7666 --> TODO </td><td> <b>Shared data in a European Health Data Space using the example of digital health applications</b><br/> <i>(Fabiola Böning)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_7666.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 8210 --> TODO </td><td> <b>Towards better whistleblowing processes: understanding  privacy risks and resulting harms</b><br/> <i>(Samuel Wairimu)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_8210.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 8265 --> TODO </td><td> <b>Economics of Privacy and the Relation to Users’ Trust</b><br/> <i>(Vera Schmitt, Tingyu Song and Danila Ferents)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_8265.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 9899 --> TODO </td><td> <b>A Framework for Exploring Personal Data Transparency from a Theoretical Perspective – Workshop Proposal –</b><br/> <i>(Anette Siebenkäs)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_9899.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
<tr><td><!-- 9938 --> TODO </td><td> <b>Compliance By Design: Balancing Data Protection, Cybersecurity and AI Regulation in Software and System Development</b><br/> <i>(Bjørn Aslak Juliussen)</i> </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_9938.pdf"><img src="/assets/images/pdficon.png" border="0"></a></td></tr>
</tbody>
</table>

<table>
<thead><tr><td> </td><td> </td><td> </td></tr></thead>
<tbody>
<tr><td align="right"> TODO </td><td> Private Training Approaches - A Primer (Jenni Reuben and Ala Sarah Alaqra) </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf">paper</a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td> &nbsp;</td></tr>
<tr><td align="right"> TODO </td><td> Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges (Marcela Tuler de Oliveira and Elyas Khorasani) </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf">paper</a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td> &nbsp;</td></tr>
</tbody>
</table>

** Session 2

<table>
<thead><tr><td> </td><td> </td><td> </td></tr></thead>
<tbody>
<tr><td align="right"> TODO </td><td> Private Training Approaches - A Primer (Jenni Reuben and Ala Sarah Alaqra) </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf">paper</a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td> &nbsp;</td></tr>
<tr><td align="right"> TODO </td><td> Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges (Marcela Tuler de Oliveira and Elyas Khorasani) </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf">paper</a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td> &nbsp;</td></tr>
</tbody>
</table>

<table>
<thead><tr><td> </td><td> </td><td> </td></tr></thead>
<tbody>
<tr><td align="right"> TODO </td><td> Private Training Approaches - A Primer (Jenni Reuben and Ala Sarah Alaqra) </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf">paper</a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td> &nbsp;</td></tr>
<tr><td align="right"> TODO </td><td> Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges (Marcela Tuler de Oliveira and Elyas Khorasani) </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf">paper</a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td> &nbsp;</td></tr>
</tbody>
</table>

<table>
<thead><tr><td> </td><td> </td><td> </td></tr></thead>
<tbody>
<tr><td align="right"> TODO </td><td> Private Training Approaches - A Primer (Jenni Reuben and Ala Sarah Alaqra) </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf">paper</a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td> &nbsp;</td></tr>
<tr><td align="right"> TODO </td><td> Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges (Marcela Tuler de Oliveira and Elyas Khorasani) </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf">paper</a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td> &nbsp;</td></tr>
</tbody>
</table>

### Wednesday, Aug 9th, 2023

<table>
<tr><td align="right"> TODO </td><td> Private Training Approaches - A Primer (Jenni Reuben and Ala Sarah Alaqra) </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf">paper</a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td> &nbsp;</td></tr>
<tr><td align="right"> TODO </td><td> Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges (Marcela Tuler de Oliveira and Elyas Khorasani) </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf">paper</a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td> &nbsp;</td></tr>
</table>

### Thursday, Aug 10th, 2023

<table>
<tr><td align="right"> TODO </td><td> Private Training Approaches - A Primer (Jenni Reuben and Ala Sarah Alaqra) </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf">paper</a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td> &nbsp;</td></tr>
<tr><td align="right"> TODO </td><td> Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges (Marcela Tuler de Oliveira and Elyas Khorasani) </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf">paper</a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td> &nbsp;</td></tr>
</table>

### Friday, Aug 11th, 2023

<table>
<tr><td align="right"> TODO </td><td> Private Training Approaches - A Primer (Jenni Reuben and Ala Sarah Alaqra) </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_401.pdf">paper</a></td></tr><tr><td>&nbsp;</td><td> Rapid proliferation of Machine Learning (ML) systems in today online services and applications have given rise to privacy preserving machine learning research. In the tutorial we present a primer understanding of general design patterns when it comes to private training of ML models, by drawing in research works from the state-of-the art private learning methods. We divide the tutorial into two parts, first the knowledge on the topic is introduced to the participants, which later is followed up through a hands-on exercise. </td><td> &nbsp;</td></tr>
<tr><td align="right"> TODO </td><td> Digital identity solutions to allow distributed access control mechanisms in cross-organisation data-sharing: Addressing privacy challenges (Marcela Tuler de Oliveira and Elyas Khorasani) </td><td> <a href="/assets/papers/2023/IFIPSC_2023_Extended_Abstract_432.pdf">paper</a></td></tr><tr><td>&nbsp;</td><td> In this workshop, we will present SmartAccess [1], a distributed Attribute-Based Access Control system based on Smart Contracts and Distributed Ledger Technology (DLT) that allows joint data controllers to define and enforce access control policies in consensus with transparency and auditability. Then we will explore the privacy challenges regarding the authentication and authorisation phase and potential solutions, including European Digital Identity. The session will be interactive, with participants working in groups to propose digital identity solutions to the privacy issues identified in the presentation (with compliance to the eIDAS framework ideally or other frameworks). This workshop is directed at a multidisciplinary audience, and participants from any field can be involved and give their contributions. </td><td> &nbsp;</td></tr>
</table>
